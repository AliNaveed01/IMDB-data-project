{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ms\n",
      "[nltk_data]     Links\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Avatar is one of the best films of the year. T...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>7.1</td>\n",
       "      <td>this movie is amazing. It is original, full of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>6.8</td>\n",
       "      <td>I wasted 3 important hours of my life watching...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>8.5</td>\n",
       "      <td>This movie is a work of art. The finest sequel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>7.1</td>\n",
       "      <td>This is by the far worst piece of cr4p I've ev...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of Movie    Year  \\\n",
       "0                                            Avatar   2009.0   \n",
       "1          Pirates of the Caribbean: At World's End   2007.0   \n",
       "2                                           Spectre   2015.0   \n",
       "3                             The Dark Knight Rises   2012.0   \n",
       "4  Star Wars: Episode VII - The Force Awakens    ...  2015.0   \n",
       "\n",
       "                             Genre  Rating  \\\n",
       "0  Action|Adventure|Fantasy|Sci-Fi     7.9   \n",
       "1         Action|Adventure|Fantasy     7.1   \n",
       "2        Action|Adventure|Thriller     6.8   \n",
       "3                  Action|Thriller     8.5   \n",
       "4                      Documentary     7.1   \n",
       "\n",
       "                                              review sentiment  \n",
       "0  Avatar is one of the best films of the year. T...  positive  \n",
       "1  this movie is amazing. It is original, full of...  positive  \n",
       "2  I wasted 3 important hours of my life watching...  negative  \n",
       "3  This movie is a work of art. The finest sequel...  positive  \n",
       "4  This is by the far worst piece of cr4p I've ev...  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data1=pd.read_csv(r\"C:\\Users\\Mohammad Noor Malik\\Downloads\\IMDB data.csv\")\n",
    "data=pd.read_excel('Movies with reviews.xlsx') \n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', str(text))\n",
    "    #x = re.sub('[^a-zA-Z]', '', str(x))\n",
    "\n",
    "#cleaning the text\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "\n",
    "data['review']=data['review'].apply(remove_between_square_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Rating</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Avatar is one of the best films of the year Th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>7.1</td>\n",
       "      <td>this movie is amazing It is original full of t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>6.8</td>\n",
       "      <td>I wasted 3 important hours of my life watching...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>8.5</td>\n",
       "      <td>This movie is a work of art The finest sequel ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens    ...</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>7.1</td>\n",
       "      <td>This is by the far worst piece of cr4p Ive eve...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>6.6</td>\n",
       "      <td>sadlythis is not the best of the movies to wat...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Action|Adventure|Romance</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Tobie was is and will be the best spidie in th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of Movie    Year  \\\n",
       "0                                            Avatar   2009.0   \n",
       "1          Pirates of the Caribbean: At World's End   2007.0   \n",
       "2                                           Spectre   2015.0   \n",
       "3                             The Dark Knight Rises   2012.0   \n",
       "4  Star Wars: Episode VII - The Force Awakens    ...  2015.0   \n",
       "5                                       John Carter   2012.0   \n",
       "6                                      Spider-Man 3   2007.0   \n",
       "\n",
       "                             Genre  Rating  \\\n",
       "0  Action|Adventure|Fantasy|Sci-Fi     7.9   \n",
       "1         Action|Adventure|Fantasy     7.1   \n",
       "2        Action|Adventure|Thriller     6.8   \n",
       "3                  Action|Thriller     8.5   \n",
       "4                      Documentary     7.1   \n",
       "5          Action|Adventure|Sci-Fi     6.6   \n",
       "6         Action|Adventure|Romance     6.2   \n",
       "\n",
       "                                              review sentiment  \n",
       "0  Avatar is one of the best films of the year Th...  positive  \n",
       "1  this movie is amazing It is original full of t...  positive  \n",
       "2  I wasted 3 important hours of my life watching...  negative  \n",
       "3  This movie is a work of art The finest sequel ...  positive  \n",
       "4  This is by the far worst piece of cr4p Ive eve...  negative  \n",
       "5  sadlythis is not the best of the movies to wat...  negative  \n",
       "6  Tobie was is and will be the best spidie in th...  positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(remove_special_characters)\n",
    "data.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('final project.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"shan't\", \"you'd\", 'being', 'an', 've', 'hadn', 'who', 'were', \"wasn't\", 'above', 'ourselves', 'they', 'hers', 'mightn', 'theirs', 'our', 'have', 'couldn', 'not', 'now', 'its', 'no', 'just', 'his', 'again', 'from', 'that', 'down', \"weren't\", 'will', 'are', 'more', 'only', 'during', 'did', \"needn't\", 'until', 'both', 'a', 'and', 'so', \"couldn't\", 'me', 'about', 'do', 'once', \"you're\", \"you've\", 'ain', 'i', 'to', 'most', 'has', 'mustn', 'shan', 'but', 'if', 'how', 'you', 'myself', 'the', 'into', 'in', 'yourselves', 'before', 'own', 'those', 'haven', 'any', 'o', 'with', 'my', 'nor', 'between', 'wouldn', 'each', \"don't\", 'm', 'himself', 'their', \"shouldn't\", 'some', 'or', 'yourself', 'your', \"mightn't\", 'aren', 'on', 'll', 'don', 'through', 'shouldn', 'under', 'hasn', 'ma', 'wasn', 'when', 'themselves', 'same', 'was', 'y', 'out', 'of', \"should've\", 'what', 'is', 'over', 'isn', \"haven't\", 'than', 'very', 's', \"hadn't\", 'whom', 'as', 're', 'am', 'such', 'why', 'against', \"you'll\", \"wouldn't\", 'these', 'does', 'few', 'while', 'below', 't', 'other', 'he', \"it's\", 'where', 'didn', 'should', 'doing', \"hasn't\", \"doesn't\", 'too', 'weren', 'at', \"won't\", 'be', 'there', 'by', 'off', 'ours', 'we', 'him', 'it', 'itself', 'had', 'up', 'all', 'been', \"mustn't\", 'after', 'doesn', 'further', 'needn', \"aren't\", 'herself', \"she's\", 'can', 'having', \"didn't\", \"that'll\", 'd', \"isn't\", 'them', 'which', 'this', 'then', 'because', 'yours', 'here', 'her', 'won', 'for', 'she'}\n"
     ]
    }
   ],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "data['review']=data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying stemming for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitiing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4894 entries, 0 to 4999\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Name of Movie  4894 non-null   object \n",
      " 1   Year           4894 non-null   float64\n",
      " 2   Genre          4894 non-null   object \n",
      " 3   Rating         4894 non-null   float64\n",
      " 4   review         4894 non-null   object \n",
      " 5   sentiment      4894 non-null   object \n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 267.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#drop the null values in Year\n",
    "data.dropna(subset=['Year'],inplace=True)\n",
    "data.dropna(subset = ['sentiment']  , inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seri random seemingli insignific theft sister board hous miss lemon quit agit ring light bulb rucksack lighter stethoscop shoe seem rhyme reason miss lemon ask employ great belgian detect hercul poirot look matter poirot see someth far sinist miss lemon could imagin poirot fear confirm one student live board hous found murder poirot bring killer justicebr br hickori dickori dock solid spectacular entri long run poirot seri appreci faith script agatha christi origin stori realiz certain liberti taken appreci effort nonetheless major point mysteri petti theft board hous student rip rucksack cours poirot abil see someth sinist go actual happen except cast student almost pictur damian lewi jessica lloyd standout among group mush alway enjoy david suchet poirot get real kick episod phillip jackson inspector japp paulin moran miss lemon episod real treat miss lemon get screen time usual final enjoy use ever present mous observ activ hostel fun littl play hickori dickori dock titlebr br realiz rewatch hickori dickori dock tremend influenc agatha christi work highli styliz italian mysteri film gialli 60 70 take murder mr nicoleti exampl bump graphic natur scene would someth straight earli 70 giallo fact entir plot hickori dickori dock could use giallo convolut interest enough work'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_reviews=data.review[:2447]\n",
    "norm_train_reviews[0]\n",
    "norm_test_reviews=data.review[2447:]\n",
    "norm_test_reviews[2555]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF to statistically measure how important a word is in a collection of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (2447, 493550)\n",
      "Tfidf_test: (2447, 493550)\n"
     ]
    }
   ],
   "source": [
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelBinarizer converts input labels into binary label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4894, 1)\n"
     ]
    }
   ],
   "source": [
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_sentiments: (2447, 1)\n",
      "test_sentiments: (2447, 1)\n"
     ]
    }
   ],
   "source": [
    "train_sentiments=sentiment_data[:2447]\n",
    "test_sentiments=sentiment_data[2447:]\n",
    "#make sure that both train and test sentiments are of same shape\n",
    "print('train_sentiments:',train_sentiments.shape)\n",
    "print('test_sentiments:',test_sentiments.shape)\n",
    "#if they are not of same shape then use ravel() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ms Links\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#fitting the svm for tfidf features\n",
    "mnb=MultinomialNB()\n",
    "mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for tfidf features\n",
    "mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Accuracy Score ->  68.08336738863915\n"
     ]
    }
   ],
   "source": [
    "#Use accuracy_score function to get the accuracy\n",
    "print(\"Tfidf Accuracy Score -> \",accuracy_score(test_sentiments,mnb_tfidf_predict)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_tfidf_score : 0.6808336738863915\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "#Accuracy score for tfidf features\n",
    "mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "#mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\",mnb_tfidf_score)\n",
    "#if it is throwing error then use ravel() function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.71      0.62      0.66      1246\n",
      "    Negative       0.65      0.74      0.70      1201\n",
      "\n",
      "    accuracy                           0.68      2447\n",
      "   macro avg       0.68      0.68      0.68      2447\n",
      "weighted avg       0.68      0.68      0.68      2447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for tfidf features\n",
    "mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fd60b8bb15377d59e74e9fea1e7409c02a309b91caf5779becf2247a2e38203"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
